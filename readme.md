# Feature Engineering Module

Content for 2 weeks of class (10 days).

<table>
  <!----------------------------------- Week 1 ----------------------------------->
  <tr>
    <th width="200" rowspan="5"><h3>Week 1</h3></th>
      <td><a href="/01.%20Robust%20ML%20pipeline">1. Robust ML (Tree Models, Mult Models, Validation, ColumnTransformer, Pipelines)</a></td></tr>
  <tr><td><a href="/02.%20Data%20Cleaning%20-%20Missings%20%26%20Outliers">2. Data Cleaning: Missings & Outliers (Drop vars, impute vars)</a></td></tr>
  <tr><td><a href="/03.%20Numerical%20Encoding">3. Numerical encodings (MinMaxScaler, StandardScaler, BoxCox, QuantileTransformer)</a></td></tr>
  <tr><td><a href="/04.%20Categorical%20Encoding">4. Categorical encodings (Ordinal, Binary, OneHot, Mean Enc., CatBoost)</a></td></tr>
  <tr><td><a href="/05.%20Feature%20Selection%20%26%20Dim%20Reduction">5. Feature Selection & Dim Reduction (PCA, tSNE, UMAP, VarianceThreshold)</a></td></tr>

  <!----------------------------------- Week 2 ----------------------------------->
  <tr>
    <th width="200" rowspan="5"><h3>Week 2</h3></th>
      <td><a href="/06.%20Text%20Encoding">6. FE for NLP (BoW, TFIDF, N-Grams)</a></td></tr>
  <tr><td><a href="/07.%20Date%20Encoding">7. FE for Time Series (lag features, tsfresh)</a></td></tr>
  <tr><td><a href="/08.%20Geoposition%20Encoding">8. FE for Geographic data (lat, lon. population)</a></td></tr>
  <tr><td><a href="/09.%20Combine%20tables">9. FE for Several tables (manually merge & join, featuretools)</a></td></tr>
  <tr><td>10. Kaggle challenge</td></tr>

</table>
